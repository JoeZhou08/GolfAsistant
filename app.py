import streamlit as st
import cv2
import numpy as np
import matplotlib.pyplot as plt
import os
import mediapipe as mp
from io import BytesIO
from PIL import Image
import traceback
import time

# --- 1. æ›œçŸ³é»‘é‡‘ UI æ¶æ„ ---
st.set_page_config(page_title="GolfAsistant | Black Gold", layout="wide", initial_sidebar_state="expanded")

st.markdown("""
    <style>
    .stApp { background-color: #121212; color: #FFFFFF; }
    [data-testid="stSidebar"] { background-color: #080808 !important; border-right: 3px solid #D4AF37 !important; }
    [data-testid="stSidebar"] .stMarkdown h1, [data-testid="stSidebar"] .stMarkdown h2, 
    [data-testid="stSidebar"] .stMarkdown h3, [data-testid="stSidebar"] label {
        color: #D4AF37 !important; font-weight: 800 !important;
    }
    div.stButton > button:first-child {
        background: linear-gradient(135deg, #D4AF37 0%, #8A6D3B 100%) !important;
        color: #000000 !important; border: 2px solid #FFD700 !important;
        border-radius: 4px !important; width: 100% !important;
    }
    .report-box { border: 1px solid #D4AF37; border-radius: 8px; padding: 30px; background: #1A1A1A; margin-bottom: 30px; }
    section[data-testid="stFileUploadDropzone"] { background-color: #222222 !important; border: 1px dashed #D4AF37 !important; }
    [data-testid="stMetric"] { background-color: #000000 !important; border: 1px solid #D4AF37 !important; }
    </style>
    """, unsafe_allow_html=True)

TEMP_DIR = "temp_output"
if not os.path.exists(TEMP_DIR): 
    os.makedirs(TEMP_DIR)

# --- 2. AI æ·±åº¦åˆ†ææ ¸å¿ƒå¼•æ“ ---

def get_action_data(video_path):
    import mediapipe as mp
    from mediapipe.python.solutions import pose as mp_pose
    
    # å†æ¬¡ç¡®è®¤æ–‡ä»¶å­˜åœ¨ä¸”ä¸ä¸ºç©º
    if not os.path.exists(video_path) or os.path.getsize(video_path) == 0:
        return np.full(100, 0.5), [0, 20, 40, 60, 80, 99], (0, 99), 30

    y_coords = []
    cap = cv2.VideoCapture(video_path)
    fps = cap.get(cv2.CAP_PROP_FPS) or 30
    
    with mp_pose.Pose(
        static_image_mode=False, 
        min_detection_confidence=0.4, 
        model_complexity=1 
    ) as pose:
        while cap.isOpened():
            ret, frame = cap.read()
            if not ret: break
            
            # ç¼©æ”¾å‡è´Ÿ
            h, w = frame.shape[:2]
            if w > 640:
                frame = cv2.resize(frame, (640, int(h * (640 / w))))
            
            rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            results = pose.process(rgb_frame)
            
            if results.pose_landmarks:
                lm = results.pose_landmarks.landmark
                # å³æ‰‹è…•ä¼˜å…ˆï¼Œå·¦æ‰‹è…•å…œåº•
                y = lm[16].y if lm[16].visibility > 0.3 else lm[15].y
                y_coords.append(y)
            else:
                y_coords.append(np.nan)
    cap.release()

    arr = np.array(y_coords)
    if len(arr) == 0 or np.all(np.isnan(arr)):
        return np.full(100, 0.5), [0, 20, 40, 60, 80, 99], (0, 99), fps

    mask = np.isnan(arr)
    if np.any(mask) and not np.all(mask):
        arr[mask] = np.interp(np.flatnonzero(mask), np.flatnonzero(~mask), arr[~mask])
    
    dy = np.abs(np.gradient(arr))
    moving = np.where(dy > (np.max(dy) * 0.1))[0]
    start_f, end_f = (moving[0], moving[-1]) if len(moving) > 0 else (0, len(arr)-1)
    
    return arr, np.linspace(start_f, end_f, 6).astype(int), (start_f, end_f), fps

def render_premium_video(video_path, y_data, swing_window, fps):
    cap = cv2.VideoCapture(video_path)
    w, h = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)), int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    ts = int(time.time())
    raw_out = os.path.join(TEMP_DIR, f"raw_{ts}.mp4")
    final_out = os.path.join(TEMP_DIR, f"final_{ts}.mp4")
    
    out = cv2.VideoWriter(raw_out, cv2.VideoWriter_fourcc(*'mp4v'), fps, (w + 400, h))
    
    for i in range(len(y_data)):
        ret, frame = cap.read()
        if not ret: break
        fig, ax = plt.subplots(figsize=(4, h/100), dpi=100)
        fig.patch.set_facecolor('#000000')
        ax.plot(y_data, color='#D4AF37', linewidth=3)
        ax.axvline(x=i, color='#FFFFFF', linewidth=2)
        ax.invert_yaxis()
        ax.axis('off')
        fig.canvas.draw()
        graph_img = cv2.cvtColor(np.array(fig.canvas.buffer_rgba()), cv2.COLOR_RGBA2BGR)
        plt.close(fig)
        out.write(np.hstack((frame, cv2.resize(graph_img, (400, h)))))
    
    cap.release()
    out.release()
    
    os.system(f'ffmpeg -y -i "{raw_out}" -an -vcodec libx264 -crf 28 "{final_out}"')
    return final_out if os.path.exists(final_out) else raw_out

def get_pose_frame(video_path, frame_idx):
    cap = cv2.VideoCapture(video_path)
    cap.set(cv2.CAP_PROP_POS_FRAMES, frame_idx)
    ret, frame = cap.read(); cap.release()
    if not ret: return None
    
    with mp.solutions.pose.Pose(static_image_mode=True, model_complexity=1) as pose:
        rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        res = pose.process(rgb)
        if res.pose_landmarks:
            mp.solutions.drawing_utils.draw_landmarks(rgb, res.pose_landmarks, mp.solutions.pose.POSE_CONNECTIONS)
    return rgb

# --- 3. é¡µé¢é€»è¾‘ ---

with st.sidebar:
    st.title("ğŸ† GolfAsistant")
    st.markdown("å°Šäº«çº§ AI æ·±åº¦åˆ†æå¯¹æ¯”ç³»ç»Ÿ")
    st.markdown("---")
    u_file = st.file_uploader("å­¦å‘˜ç»ƒä¹ è§†é¢‘", type=["mp4", "mov"])
    p_file = st.file_uploader("èŒä¸šå¯¹æ ‡è§†é¢‘", type=["mp4", "mov"])
    st.markdown("---")
    analyze_btn = st.button("å¼€å¯ AI æ·±åº¦åˆ†æ âš¡")

if u_file and p_file:
    if analyze_btn:
        try:
            with st.status("æ­£åœ¨è¿›è¡Œ AI é¢„å¤„ç†...", expanded=True) as status:
                ts = int(time.time())
                # åŸå§‹ä¸Šä¼ æ–‡ä»¶
                u_p_raw = os.path.join(TEMP_DIR, f"u_raw_{ts}.mp4")
                p_p_raw = os.path.join(TEMP_DIR, f"p_raw_{ts}.mp4")
                # FFmpeg å¤„ç†åçš„æ ‡å‡†æ–‡ä»¶ï¼ˆå»éŸ³è½¨ã€ç»Ÿä¸€ç¼–ç ï¼‰
                u_p = os.path.join(TEMP_DIR, f"u_{ts}.mp4")
                p_p = os.path.join(TEMP_DIR, f"p_{ts}.mp4")

                with open(u_p_raw, "wb") as f: f.write(u_file.getbuffer())
                with open(p_p_raw, "wb") as f: f.write(p_file.getbuffer())

                # --- FFmpeg æ ¸å¿ƒé¢„å¤„ç†ï¼šé™éŸ³ + æ ‡å‡†åŒ– ---
                st.write("æ­£åœ¨ä¼˜åŒ–è§†é¢‘ç¼–ç å¹¶ç§»é™¤éŸ³è½¨...")
                os.system(f'ffmpeg -y -i "{u_p_raw}" -an -vcodec libx264 -crf 23 "{u_p}"')
                os.system(f'ffmpeg -y -i "{p_p_raw}" -an -vcodec libx264 -crf 23 "{p_p}"')
                
                # å¦‚æœè½¬ç å¤±è´¥ï¼Œåˆ™ä½¿ç”¨åŸå§‹æ–‡ä»¶ï¼ˆå…œåº•ï¼‰
                if not os.path.exists(u_p): u_p = u_p_raw
                if not os.path.exists(p_p): p_p = p_p_raw

                st.write("æ­£åœ¨æå– AI éª¨éª¼ç‰¹å¾ç‚¹...")
                u_data, u_idx, u_win, u_fps = get_action_data(u_p)
                p_data, p_idx, p_win, p_fps = get_action_data(p_p)

                # æ¨¡å—1: æŒ‡æ ‡æ˜¾ç¤º
                c1, c2, c3 = st.columns(3)
                c1.metric("å­¦å‘˜æŒ¥æ†æ—¶é•¿", f"{u_win[1]-u_win[0]} Frames")
                c2.metric("èŒä¸šé€‰æ‰‹æ—¶é•¿", f"{p_win[1]-p_win[0]} Frames")
                match = max(0, 100-abs((u_win[1]-u_win[0])-(p_win[1]-p_win[0])))
                c3.metric("AI å¯¹é½åŒ¹é…åº¦", f"{match}%")

                # æ¨¡å—2: è½¨è¿¹å¯¹æ¯”å›¾
                st.markdown('<div class="report-box"><h3>ğŸ“Š æ‰‹è…• AI è½¨è¿¹å¯¹æ¯”åˆ†æ</h3>', unsafe_allow_html=True)
                fig_t, ax = plt.subplots(figsize=(12, 4))
                fig_t.patch.set_facecolor('#1A1A1A')
                ax.plot(np.linspace(0, 100, len(u_data)), u_data, label="Student", color="#FFFFFF", linewidth=3)
                ax.plot(np.linspace(0, 100, len(p_data)), p_data, label="Pro", color="#D4AF37", linestyle="--", linewidth=3)
                ax.invert_yaxis()
                ax.set_facecolor('#1A1A1A')
                ax.tick_params(colors='#D4AF37')
                ax.legend(facecolor='#000000', edgecolor='#D4AF37', labelcolor='white')
                st.pyplot(fig_t)
                buf_track = BytesIO(); fig_t.savefig(buf_track, format="png"); plt.close(fig_t)
                st.markdown('</div>', unsafe_allow_html=True)

                # æ¨¡å—3: å…³é”®å¸§çŸ©é˜µ
                st.markdown('<div class="report-box"><h3>ğŸ“¸ AI å…³é”®é˜¶æ®µå¯¹æ¯” (Stage 1-6)</h3>', unsafe_allow_html=True)
                m_imgs = []
                blank_img = np.zeros((500, 350, 3), dtype=np.uint8) 
                for i in range(6):
                    img_u = get_pose_frame(u_p, u_idx[i])
                    img_p = get_pose_frame(p_p, p_idx[i])
                    res_u = cv2.resize(img_u, (350, 500)) if img_u is not None else blank_img
                    res_p = cv2.resize(img_p, (350, 500)) if img_p is not None else blank_img
                    m_imgs.append(np.hstack((res_u, res_p)))
                
                r1, r2 = np.hstack(m_imgs[:3]), np.hstack(m_imgs[3:])
                full_m = np.vstack((r1, r2))
                st.image(full_m, use_container_width=True)
                buf_matrix = BytesIO(); Image.fromarray(full_m).save(buf_matrix, format="png")
                st.markdown('</div>', unsafe_allow_html=True)

                # æ¨¡å—4: ç”Ÿæˆåˆ†æå½•å½±
                v_path = render_premium_video(u_p, u_data, u_win, u_fps)
                st.video(v_path)
                
                status.update(label="âœ… AI æ·±åº¦åˆ†ææŠ¥å‘Šå°±ç»ª", state="complete")

            # ä¾§è¾¹æ ä¸‹è½½
            with st.sidebar:
                st.markdown("---")
                st.download_button("ğŸ“Š å¯¼å‡ºè½¨è¿¹æ›²çº¿", buf_track.getvalue(), "track.png", use_container_width=True)
                st.download_button("ğŸ“¸ å¯¼å‡ºå¯¹æ¯”å¿«ç…§", buf_matrix.getvalue(), "matrix.png", use_container_width=True)
                with open(v_path, "rb") as f:
                    st.download_button("ğŸ¥ å¯¼å‡ºåˆ†æå½•å½±", f, "video.mp4", use_container_width=True)

        except Exception as e:
            st.error(f"åˆ†æå¼•æ“ä¸­æ–­: {e}")
            st.code(traceback.format_exc())
else:
    st.info("ğŸ’ è¯·åœ¨å·¦ä¾§ä¸Šä¼ å­¦å‘˜å’Œ Pro çš„è§†é¢‘ï¼Œç³»ç»Ÿå°†è‡ªåŠ¨å¯¹é½å¹¶åˆ†æã€‚")
